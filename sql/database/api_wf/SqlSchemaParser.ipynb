{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c53280",
   "metadata": {},
   "source": [
    "# MySQL Schema Parser with Gemini Flash\n",
    "\n",
    "This notebook creates a parser for complex MySQL table schemas, handling features like:\n",
    "- Type modifiers (UNSIGNED, etc)\n",
    "- COLLATE clauses\n",
    "- Column COMMENTS\n",
    "- Generated columns (AS expressions)\n",
    "- Complex indexes with BTREE\n",
    "- Table-level constraints\n",
    "\n",
    "We'll use this to parse schemas like `plan_impacts` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e1f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample SQL schema to parse\n",
    "sql_schema = \"\"\"\n",
    "CREATE TABLE `plan_impacts` (\n",
    "    `id` INT UNSIGNED NOT NULL AUTO_INCREMENT,\n",
    "    `plan_id` INT UNSIGNED NOT NULL,\n",
    "    `file_path` VARCHAR(500) NOT NULL COLLATE 'utf8mb4_general_ci',\n",
    "    `phase` VARCHAR(20) NOT NULL DEFAULT 'idea' COLLATE 'utf8mb4_general_ci',\n",
    "    `change_type` VARCHAR(20) NOT NULL COLLATE 'utf8mb4_general_ci',\n",
    "    `status` VARCHAR(20) NOT NULL DEFAULT 'pending' COLLATE 'utf8mb4_general_ci',\n",
    "    `description` TEXT NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',\n",
    "    `batch_id` VARCHAR(36) NULL DEFAULT NULL COMMENT 'Groups related file changes together' COLLATE 'utf8mb4_general_ci',\n",
    "    `affected_apps` JSON NULL DEFAULT NULL COMMENT 'Array of apps affected by the change',\n",
    "    `auto_generated` TINYINT(1) NOT NULL DEFAULT '0' COMMENT 'True if auto-generated impact',\n",
    "    `cross_app_analysis` JSON NULL DEFAULT NULL COMMENT 'Cross-app dependency analysis results',\n",
    "    `fileName` VARCHAR(255) AS (substring_index(`file_path`,_utf8mb4'/',-(1))) stored,\n",
    "    `fileFolder` VARCHAR(255) AS (substr(`file_path`,1,((length(`file_path`) - length(substring_index(`file_path`,_utf8mb4'/',-(1)))) - 1))) stored,\n",
    "    `created_at` TIMESTAMP NULL DEFAULT NULL,\n",
    "    `created_by` VARCHAR(50) NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',\n",
    "    `updated_at` TIMESTAMP NULL DEFAULT NULL,\n",
    "    `updated_by` VARCHAR(50) NULL DEFAULT NULL COLLATE 'utf8mb4_general_ci',\n",
    "    PRIMARY KEY (`id`) USING BTREE,\n",
    "    INDEX `idx_plan_impacts_plan_id` (`plan_id`) USING BTREE,\n",
    "    INDEX `idx_plan_impacts_file` (`file_path`) USING BTREE,\n",
    "    INDEX `Idx_plan_impacts_phase` (`phase`) USING BTREE,\n",
    "    INDEX `idx_plan_impacts_folder` (`fileFolder`) USING BTREE,\n",
    "    INDEX `idx_plan_impacts_batch_id` (`batch_id`) USING BTREE,\n",
    "    INDEX `idx_plan_impacts_auto_generated` (`auto_generated`) USING BTREE,\n",
    "    CONSTRAINT `plan_impacts_ibfk_1` FOREIGN KEY (`plan_id`) REFERENCES `plans` (`id`) ON UPDATE NO ACTION ON DELETE NO ACTION\n",
    ")\n",
    "COLLATE='utf8mb4_general_ci'\n",
    "ENGINE=InnoDB\n",
    "AUTO_INCREMENT=153;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Optional, TypedDict, Union\n",
    "\n",
    "class ColumnDef(TypedDict):\n",
    "    name: str\n",
    "    type: str\n",
    "    length: Optional[int]\n",
    "    unsigned: bool\n",
    "    nullable: bool\n",
    "    default: Optional[str]\n",
    "    collate: Optional[str]\n",
    "    comment: Optional[str]\n",
    "    autoIncrement: bool\n",
    "    generated: Optional[Dict[str, str]]  # expression, type (STORED/VIRTUAL)\n",
    "\n",
    "class IndexDef(TypedDict):\n",
    "    name: str\n",
    "    columns: List[str]\n",
    "    type: str\n",
    "    using: str\n",
    "\n",
    "class ForeignKeyDef(TypedDict):\n",
    "    name: str\n",
    "    column: str\n",
    "    references: Dict[str, str]  # table, column\n",
    "    onUpdate: str\n",
    "    onDelete: str\n",
    "\n",
    "class TableSchema(TypedDict):\n",
    "    name: str\n",
    "    columns: List[ColumnDef]\n",
    "    primaryKey: Optional[IndexDef]\n",
    "    indexes: List[IndexDef]\n",
    "    foreignKeys: List[ForeignKeyDef]\n",
    "    options: Dict[str, str]\n",
    "\n",
    "class MySQLSchemaParser:\n",
    "    def parse(self, sql: str) -> TableSchema:\n",
    "        # Extract table name and main content\n",
    "        table_match = re.match(\n",
    "            r\"CREATE TABLE `(\\w+)`\\s*\\((.*)\\)\\s*(.*);\",\n",
    "            sql,\n",
    "            re.DOTALL\n",
    "        )\n",
    "        if not table_match:\n",
    "            raise ValueError(\"Invalid CREATE TABLE statement\")\n",
    "            \n",
    "        table_name = table_match.group(1)\n",
    "        columns_part = table_match.group(2)\n",
    "        table_options = table_match.group(3)\n",
    "        \n",
    "        # Split into individual definitions\n",
    "        parts = self._split_definitions(columns_part)\n",
    "        \n",
    "        # Process each part\n",
    "        columns: List[ColumnDef] = []\n",
    "        indexes: List[IndexDef] = []\n",
    "        foreign_keys: List[ForeignKeyDef] = []\n",
    "        primary_key = None\n",
    "        \n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "            if part.startswith('`'):  # Column definition\n",
    "                columns.append(self._parse_column(part))\n",
    "            elif part.startswith('PRIMARY KEY'):\n",
    "                primary_key = self._parse_primary_key(part)\n",
    "            elif part.startswith('INDEX') or part.startswith('KEY'):\n",
    "                indexes.append(self._parse_index(part))\n",
    "            elif part.startswith('CONSTRAINT') and 'FOREIGN KEY' in part:\n",
    "                foreign_keys.append(self._parse_foreign_key(part))\n",
    "                \n",
    "        # Parse table options\n",
    "        options = self._parse_table_options(table_options)\n",
    "                \n",
    "        return {\n",
    "            \"name\": table_name,\n",
    "            \"columns\": columns,\n",
    "            \"primaryKey\": primary_key,\n",
    "            \"indexes\": indexes,\n",
    "            \"foreignKeys\": foreign_keys,\n",
    "            \"options\": options\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _split_definitions(self, content: str) -> List[str]:\n",
    "        \"\"\"Split the table content into individual column/constraint definitions\"\"\"\n",
    "        parts = []\n",
    "        current = []\n",
    "        paren_level = 0\n",
    "        \n",
    "        for char in content:\n",
    "            if char == '(' and len(current) > 0:\n",
    "                paren_level += 1\n",
    "            elif char == ')' and paren_level > 0:\n",
    "                paren_level -= 1\n",
    "            elif char == ',' and paren_level == 0:\n",
    "                parts.append(''.join(current).strip())\n",
    "                current = []\n",
    "                continue\n",
    "                \n",
    "            current.append(char)\n",
    "            \n",
    "        if current:\n",
    "            parts.append(''.join(current).strip())\n",
    "            \n",
    "        return parts\n",
    "        \n",
    "    def _parse_column(self, definition: str) -> ColumnDef:\n",
    "        \"\"\"Parse a column definition line\"\"\"\n",
    "        # Base pattern for column name and type\n",
    "        pattern = (\n",
    "            r\"`(\\w+)`\\s+\"  # Column name\n",
    "            r\"(\\w+)\"       # Base type\n",
    "            r\"(?:\\((\\d+)\\))?\"  # Optional length\n",
    "            r\"(\\s+UNSIGNED)?\"  # UNSIGNED modifier\n",
    "            r\"(\\s+(?:NOT\\s+)?NULL)?\"  # Nullability\n",
    "            r\"(?:\\s+DEFAULT\\s+([^,\\s]+))?\"  # Default value\n",
    "            r\"(?:\\s+COLLATE\\s+'([^']+)')?\"  # Collation\n",
    "            r\"(?:\\s+COMMENT\\s+'([^']+)')?\"  # Comment\n",
    "            r\"(?:\\s+AUTO_INCREMENT)?\"  # Auto increment\n",
    "            r\"(?:\\s+AS\\s+\\((.*?)\\)\\s+(STORED|VIRTUAL))?\"  # Generated column\n",
    "        )\n",
    "        \n",
    "        match = re.match(pattern, definition, re.IGNORECASE | re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Invalid column definition: {definition}\")\n",
    "            \n",
    "        name, type_, length, unsigned, nullable, default, collate, comment, expr, gen_type = match.groups()\n",
    "        \n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"type\": type_.upper(),\n",
    "            \"length\": int(length) if length else None,\n",
    "            \"unsigned\": bool(unsigned),\n",
    "            \"nullable\": not (nullable and \"NOT NULL\" in nullable.upper()),\n",
    "            \"default\": default.strip(\"'\") if default else None,\n",
    "            \"collate\": collate,\n",
    "            \"comment\": comment,\n",
    "            \"autoIncrement\": \"AUTO_INCREMENT\" in definition.upper(),\n",
    "            \"generated\": {\"expression\": expr, \"type\": gen_type} if expr else None\n",
    "        }\n",
    "        \n",
    "    def _parse_primary_key(self, definition: str) -> IndexDef:\n",
    "        \"\"\"Parse PRIMARY KEY definition\"\"\"\n",
    "        match = re.match(r\"PRIMARY KEY\\s*\\(`([^`]+)`\\)(?:\\s+USING\\s+(\\w+))?\", definition)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Invalid PRIMARY KEY definition: {definition}\")\n",
    "            \n",
    "        column, using = match.groups()\n",
    "        return {\n",
    "            \"name\": \"PRIMARY\",\n",
    "            \"columns\": [column],\n",
    "            \"type\": \"PRIMARY\",\n",
    "            \"using\": using or \"BTREE\"\n",
    "        }\n",
    "        \n",
    "    def _parse_index(self, definition: str) -> IndexDef:\n",
    "        \"\"\"Parse INDEX definition\"\"\"\n",
    "        pattern = r\"(?:INDEX|KEY)\\s+`([^`]+)`\\s*\\(`([^`]+)`\\)(?:\\s+USING\\s+(\\w+))?\"\n",
    "        match = re.match(pattern, definition)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Invalid INDEX definition: {definition}\")\n",
    "            \n",
    "        name, column, using = match.groups()\n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"columns\": [col.strip() for col in column.split(',')],\n",
    "            \"type\": \"INDEX\",\n",
    "            \"using\": using or \"BTREE\"\n",
    "        }\n",
    "        \n",
    "    def _parse_foreign_key(self, definition: str) -> ForeignKeyDef:\n",
    "        \"\"\"Parse FOREIGN KEY constraint\"\"\"\n",
    "        pattern = (\n",
    "            r\"CONSTRAINT\\s+`([^`]+)`\\s+\"\n",
    "            r\"FOREIGN KEY\\s*\\(`([^`]+)`\\)\\s+\"\n",
    "            r\"REFERENCES\\s+`([^`]+)`\\s*\\(`([^`]+)`\\)\\s*\"\n",
    "            r\"(?:ON DELETE\\s+(\\w+(?:\\s+\\w+)?))?\\s*\"\n",
    "            r\"(?:ON UPDATE\\s+(\\w+(?:\\s+\\w+)?))?\")\n",
    "            \n",
    "        match = re.match(pattern, definition)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Invalid FOREIGN KEY definition: {definition}\")\n",
    "            \n",
    "        name, column, ref_table, ref_column, on_delete, on_update = match.groups()\n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"column\": column,\n",
    "            \"references\": {\n",
    "                \"table\": ref_table,\n",
    "                \"column\": ref_column\n",
    "            },\n",
    "            \"onDelete\": on_delete or \"NO ACTION\",\n",
    "            \"onUpdate\": on_update or \"NO ACTION\"\n",
    "        }\n",
    "        \n",
    "    def _parse_table_options(self, options_str: str) -> Dict[str, str]:\n",
    "        \"\"\"Parse table-level options\"\"\"\n",
    "        options = {}\n",
    "        \n",
    "        if \"COLLATE\" in options_str:\n",
    "            collate_match = re.search(r\"COLLATE='([^']+)'\", options_str)\n",
    "            if collate_match:\n",
    "                options[\"collate\"] = collate_match.group(1)\n",
    "                \n",
    "        if \"ENGINE\" in options_str:\n",
    "            engine_match = re.search(r\"ENGINE=(\\w+)\", options_str)\n",
    "            if engine_match:\n",
    "                options[\"engine\"] = engine_match.group(1)\n",
    "                \n",
    "        if \"AUTO_INCREMENT\" in options_str:\n",
    "            ai_match = re.search(r\"AUTO_INCREMENT=(\\d+)\", options_str)\n",
    "            if ai_match:\n",
    "                options[\"autoIncrement\"] = ai_match.group(1)\n",
    "                \n",
    "        return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e62e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parser instance and parse the schema\n",
    "parser = MySQLSchemaParser()\n",
    "result = parser.parse(sql_schema)\n",
    "\n",
    "# Pretty print the result\n",
    "print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
